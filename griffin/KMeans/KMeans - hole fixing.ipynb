{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KMeans(object):\n",
    "    def __init__(self, k=8, euclid = True):\n",
    "        self.k = k\n",
    "        if (euclid):\n",
    "            self._distance = 'euclidean'\n",
    "        else:\n",
    "            self._distance = self._distance_haversine\n",
    "    \n",
    "    def _step(self):\n",
    "        \"\"\"Compute distance, assign groups, recompute centers\"\"\"\n",
    "        distance = cdist(self.X,self.cluster_centers,metric=self._distance)\n",
    "        self.labels = distance.argmin(1)\n",
    "       # centers = np.zeros((self.k,2))\n",
    "        for cluster in range(self.k):\n",
    "            points = self.X[self.labels == cluster]\n",
    "            if len(points) == 0:\n",
    "                distance = cdist(self.X,self.cluster_centers,metric=self._distance)\n",
    "                mean_dist = np.mean(distance,0)\n",
    "                self.cluster_centers[cluster] = mean_dist.argmax()\n",
    "            else:\n",
    "                self.cluster_centers[cluster] = np.mean(points,0)\n",
    "       # self.cluster_centers = centers\n",
    "        \n",
    "    def _distance_haversine(self,a,b):\n",
    "        lat_1, lon_1, lat_2, lon_2 = map(np.radians,[a[0],a[1],b[0],b[1]])\n",
    "        d_lat = lat_2 - lat_1\n",
    "        d_lon = lon_2 - lon_1\n",
    "        \n",
    "        arc = np.sin(d_lat/2.0)**2 + np.cos(lat_1)*np.cos(lat_2)*np.sin(d_lon/2)**2\n",
    "        \n",
    "        c = 2 * np.arcsin(np.sqrt(arc))\n",
    "        km = 6372.8 * c\n",
    "        return km\n",
    "    \n",
    "    def _init_centers(self, X):\n",
    "        unique = np.unique(X, axis=0)\n",
    "        index = np.random.permutation(len(unique))[:self.k]\n",
    "        return unique[index]\n",
    "    \n",
    "    def fit(self,X, centers = None):\n",
    "        '''Expects centers to be inputted, if not random'''\n",
    "        self.labels = np.zeros(len(X))\n",
    "        self.X = X\n",
    "        if centers is not None:\n",
    "            self.cluster_centers = centers \n",
    "        else:\n",
    "            self.cluster_centers = self._init_centers(X)\n",
    "        old_centers = np.zeros((self.k,2))\n",
    "    #    self.i = 0\n",
    "        while(not np.array_equal(old_centers, self.cluster_centers)):\n",
    "            old_centers = self.cluster_centers.copy()\n",
    "            self._step()\n",
    "         #   self.i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "from geopandas import GeoDataFrame\n",
    "\n",
    "demographics = gpd.read_file('./census.geoJSON')\n",
    "\n",
    "def gen_coords(loc):\n",
    "    data = loc[1:-1].split(',')\n",
    "    data = list((np.float(data[0]), np.float(data[1])))\n",
    "    x.append(data[1])\n",
    "    y.append(data[0])\n",
    "    return [data[0],data[1]]\n",
    "\n",
    "def point_similarity(X,geo_labels, euc_labels,k):\n",
    "    '''For an inputted series of points, geodesic labels, euclidean labels, and k-value\n",
    "       returns the point-similarity index per geodesic cluster\n",
    "    '''\n",
    "\n",
    "    euc_cluster_totals = np.zeros(k,dtype=np.int)\n",
    "    geo_euc_composition = [np.zeros(k,dtype=np.int)* 1 for i in range(k)]\n",
    "    \n",
    "    for index,point in enumerate(geo_labels):\n",
    "        euc_cluster_totals[euc_labels[index]] += 1\n",
    "        geo_euc_composition[point][euc_labels[index]] += 1\n",
    "    \n",
    "    point_sim = []\n",
    "    for geo_cluster in range(k):\n",
    "        sim = 0\n",
    "        for euc_cluster in range(k):\n",
    "            matching_points = geo_euc_composition[geo_cluster][euc_cluster]\n",
    "            euc_percentage = matching_points / euc_cluster_totals[euc_cluster]\n",
    "            geo_percentage = matching_points / np.sum(geo_euc_composition[geo_cluster])\n",
    "            sim += euc_percentage * geo_percentage\n",
    "        point_sim.append(sim)\n",
    "\n",
    "    return np.array(point_sim)\n",
    "\n",
    "def minority_probability(X,cluster_number,geo_labels,demographics):\n",
    "        points = X[geo_labels == cluster_number]\n",
    "        # geoJSON puts points in Long/Lat order\n",
    "        # but points are in lat/long earlier\n",
    "        hull = shapely.geometry.multipoint.MultiPoint([[p[1],p[0]] for p in points]).convex_hull\n",
    "  \n",
    "        pop = np.zeros(7)\n",
    "        for index in range(len(demographics)):\n",
    "            census_tract = demographics.loc[index,'geometry']\n",
    "            intersect = hull.intersection(census_tract)\n",
    "            overlap = intersect.area/census_tract.area\n",
    "            if (overlap != 0):\n",
    "                pop = pop + (np.array(demographics.loc[index,['White','Black or African American', 'American Indian and Ala Native',\n",
    "                   'Asian','Native Hawaiian/other Pac Isl', 'Multiple Race',\n",
    "                   'Other Race']]) * overlap)\n",
    "        \n",
    "        if (np.all(pop ==0)):\n",
    "            return 0\n",
    "        \n",
    "        return (pop[1:]/np.sum(pop)).sum()\n",
    "\n",
    "def bias_index(X, geo_labels, euc_labels, demographics, k):\n",
    "\n",
    "    dissimilarity_index = 1 - point_similarity(X,geo_labels,euc_labels,k)\n",
    "    minority_prob = np.array([minority_probability(X,cluster,geo_labels,demographics) \n",
    "                              for cluster in range(k)])\n",
    "    \n",
    "    potential_bias = minority_prob * dissimilarity_index\n",
    "    return potential_bias.mean()\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_index(X,geodesic.labels,euclid.labels,demographics,k)\n",
    "geodesic.labels == euclid.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_2014/m_theft_july.csv\n",
      "0.0\n",
      "1\n",
      "0.0\n",
      "2\n",
      "0.0\n",
      "3\n",
      "0.0\n",
      "4\n",
      "0.0\n",
      "5\n",
      "0.0\n",
      "6\n",
      "0.0\n",
      "7\n",
      "0.0\n",
      "8\n",
      "0.0\n",
      "9\n",
      "0.0\n",
      "10\n",
      "0.0\n",
      "11\n",
      "0.0\n",
      "12\n",
      "0.0\n",
      "13\n",
      "0.0\n",
      "14\n",
      "0.0\n",
      "15\n",
      "0.0\n",
      "16\n",
      "0.0\n",
      "17\n",
      "0.0\n",
      "18\n",
      "0.0\n",
      "19\n",
      "0.0\n",
      "20\n",
      "0.0\n",
      "21\n",
      "0.0\n",
      "22\n",
      "0.0\n",
      "23\n",
      "0.0\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "holes = open('./experiment_heap/holes.txt','r')\n",
    "temp = holes.read().splitlines()\n",
    "holes.close()\n",
    "temp = np.random.permutation(temp)\n",
    "for item in temp:\n",
    "    file = item.split('-')[0] + '/' + item.split('-')[1]\n",
    "    k = int(item.split('-')[2])\n",
    "    \n",
    "    df = pd.read_csv('../data/' + file, sep =';')\n",
    "        \n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    df['Points'] = df['Location'].apply(gen_coords)\n",
    "    points = [Point(xy) for xy in zip(x,y)]\n",
    "    crs = {'init': 'epsg:4326'}\n",
    "    geo_df = GeoDataFrame(df,crs=crs, geometry=points)\n",
    "    theft_both = geo_df.copy()\n",
    "\n",
    "    test_list = []\n",
    "\n",
    "    for index in range(len(theft_both)):\n",
    "        test_list.append(df.loc[index, 'Points'])\n",
    "\n",
    "    X = np.array(test_list)\n",
    "   \n",
    "    print(file)\n",
    "    \n",
    "\n",
    "    bias_data = f'{file};{k};'\n",
    "    warnings.simplefilter('error')\n",
    "    success = 0\n",
    "    iteration = 0\n",
    "    while(success < 49):\n",
    "        try:\n",
    "            iteration +=1\n",
    "            euclid = KMeans(k=k)\n",
    "            geodesic = KMeans(k=k, euclid = 'false')\n",
    "            centers = euclid._init_centers(X)\n",
    "\n",
    "            euclid.fit(X,centers=centers)\n",
    "            geodesic.fit(X,centers=centers)\n",
    "          #  print(euclid.labels)\n",
    "          #  print(geodesic.labels)\n",
    "\n",
    "            bias = bias_index(X,geodesic.labels,euclid.labels,demographics,k)\n",
    "            print(bias)\n",
    "            bias_data += str(bias) + ';'\n",
    "            success +=1\n",
    "            print(success)\n",
    "        except Warning:\n",
    "            if (iteration > 200 and success == 0):\n",
    "                break\n",
    "            continue\n",
    "    if success == 0:\n",
    "        continue\n",
    "    folder = item.split('-')[0]\n",
    "    file_name = item.split('-')[1]\n",
    "    file_name = file_name.split('.csv')[0]\n",
    "    with open(f'./experiment_heap/{folder}_{file_name}_{k}.csv','w') as f:\n",
    "        print(f'./experiment_heap/{folder}_{file_name}_{k}.csv')\n",
    "        f.write(bias_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
